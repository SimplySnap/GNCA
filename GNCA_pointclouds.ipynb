{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPsictqtic51IWZQnFGvTWC"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "2pKyH3ozy2_M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installs"
      ],
      "metadata": {
        "id": "LvYEGqkqyzu8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNmFkzCY_skt",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#!pip install torch==2.4.0\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch_version = torch.__version__\n",
        "print(torch_version)\n",
        "scatter_src = f\"https://pytorch-geometric.com/whl/torch-{torch_version}.html\"\n",
        "sparse_src = f\"https://pytorch-geometric.com/whl/torch-{torch_version}.html\"\n",
        "\n",
        "#!pip install torch-scatter -f $scatter_src\n",
        "#!pip install torch-sparse -f $sparse_src\n",
        "!pip install torch-geometric\n",
        "import torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "khmJi3fg0BN0",
        "outputId": "418f2584-fb79-4154-b959-904780439025"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.0+cu126\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-2.9.0+cu126.html\n",
            "Collecting torch-scatter\n",
            "  Downloading torch_scatter-2.1.2.tar.gz (108 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: torch-scatter\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-scatter: filename=torch_scatter-2.1.2-cp312-cp312-linux_x86_64.whl size=3857007 sha256=7cd0a793327f8f9b220cf810f913d3a58038df922fc2c1fe2db3b501d4946b92\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/20/50/44800723f57cd798630e77b3ec83bc80bd26a1e3dc3a672ef5\n",
            "Successfully built torch-scatter\n",
            "Installing collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.2\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-2.9.0+cu126.html\n",
            "Collecting torch-sparse\n",
            "  Downloading torch_sparse-0.6.18.tar.gz (209 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.0/210.0 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-sparse) (1.16.3)\n",
            "Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from scipy->torch-sparse) (2.0.2)\n",
            "Building wheels for collected packages: torch-sparse\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hcanceled\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
            "    return func(self, options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/commands/install.py\", line 423, in run\n",
            "    _, build_failures = build(\n",
            "                        ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/wheel_builder.py\", line 319, in build\n",
            "    wheel_file = _build_one(\n",
            "                 ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/wheel_builder.py\", line 193, in _build_one\n",
            "    wheel_path = _build_one_inside_env(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/wheel_builder.py\", line 240, in _build_one_inside_env\n",
            "    wheel_path = build_wheel_legacy(\n",
            "                 ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/operations/build/wheel_legacy.py\", line 83, in build_wheel_legacy\n",
            "    output = call_subprocess(\n",
            "             ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/utils/subprocess.py\", line 151, in call_subprocess\n",
            "    line: str = proc.stdout.readline()\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/main.py\", line 80, in main\n",
            "    return command.main(cmd_args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 100, in main\n",
            "    return self._main(args)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 232, in _main\n",
            "    return run(options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 216, in exc_logging_wrapper\n",
            "    logger.debug(\"Exception information:\", exc_info=True)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1527, in debug\n",
            "    self._log(DEBUG, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1684, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1700, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1762, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1028, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/lib/python3.12/logging/handlers.py\", line 75, in emit\n",
            "    logging.FileHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1280, in emit\n",
            "    StreamHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1160, in emit\n",
            "    msg = self.format(record)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 999, in format\n",
            "    return fmt.format(record)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/utils/logging.py\", line 112, in format\n",
            "    formatted = super().format(record)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 711, in format\n",
            "    record.exc_text = self.formatException(record.exc_info)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 661, in formatException\n",
            "    traceback.print_exception(ei[0], ei[1], tb, None, sio)\n",
            "  File \"/usr/lib/python3.12/traceback.py\", line 124, in print_exception\n",
            "    te = TracebackException(type(value), value, tb, limit=limit, compact=True)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/traceback.py\", line 733, in __init__\n",
            "    self.stack = StackSummary._extract_from_extended_frame_gen(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/traceback.py\", line 418, in _extract_from_extended_frame_gen\n",
            "    for f, (lineno, end_lineno, colno, end_colno) in frame_gen:\n",
            "                                                     ^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/traceback.py\", line 355, in _walk_tb_with_full_positions\n",
            "    positions = _get_code_position(tb.tb_frame.f_code, tb.tb_lasti)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/traceback.py\", line 369, in _get_code_position\n",
            "    return next(itertools.islice(positions_gen, instruction_index // 2, None))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.13.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2025.11.12)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\n",
            "Downloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Constants\n",
        "num_cells = 1000\n",
        "feature_size = 1 #Controls how many features we are predicting in GNN. If one-dimensional GCA then keep this one\n",
        "# (density range: we flip if within density range)\n",
        "lo = 0.0\n",
        "hi = 0.4\n",
        "\n",
        "batch_size = 64 #Default in Grattarola et al. is 32\n",
        "epochs = 5000\n",
        "lr = 0.01\n",
        "\n"
      ],
      "metadata": {
        "id": "ni9OkFHI23Zn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch_geometric as pyg\n",
        "import torch.nn.functional as F # Import F for ReLU\n",
        "\n",
        "class GNCA(torch.nn.Module):\n",
        "  ''' General GNCA class, generalizable for many problem types\n",
        "  Architecture:\n",
        "    1. MLP on node embedding\n",
        "    2. Concatenation with NN on neighbors (GCN)\n",
        "    3. Postprocessing MLP on result\n",
        "  MLP pre and post have 256 size hidden units, post-processing MLP has number of units equal to state size\n",
        "  Activation function of post-processing MLP is sigmoid for binary state spaces, tanh if between -1,1, and no activation otherwise\n",
        "  '''\n",
        "  def __init__(self,dims=None,activation='relu',batch_norm=False):\n",
        "    super(GNCA, self).__init__() # Corrected super class call\n",
        "    self.hidden_dim = 256\n",
        "    self.activation = activation\n",
        "    #We want dims to be passed in as a tuple [input_dim, output_dim]\n",
        "    if dims is None:\n",
        "      self.input_dim = 2 #Assume planar embedding\n",
        "      self.output_dim = 2 #Assume output dim also planar\n",
        "    else:\n",
        "      self.input_dim = dims[0]\n",
        "      self.output_dim = dims[1]\n",
        "\n",
        "    # Now, we define our MLP layers\n",
        "    self.mlp_pre = nn.Sequential(\n",
        "            nn.Linear(self.input_dim, self.hidden_dim, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(self.hidden_dim, self.hidden_dim, bias=False),\n",
        "            nn.ReLU())\n",
        "\n",
        "    # GCN layer for neighbor aggregation\n",
        "    # The GCNConv layer expects input of shape (num_nodes, in_channels)\n",
        "    self.conv = pyg.nn.GCNConv(self.hidden_dim, self.hidden_dim, bias=False)\n",
        "\n",
        "\n",
        "    self.mlp_post = nn.Sequential(\n",
        "        nn.Linear(self.hidden_dim + self.hidden_dim, self.output_dim, bias=False), # Input dimension is sum of mlp_pre output and GCN output\n",
        "        nn.Sigmoid() # Keep Sigmoid for now, can be changed based on task\n",
        "    )\n",
        "\n",
        "  def forward(self,x,edge_index):\n",
        "    '''Forward pass (see Grattarola et al. for details)'''\n",
        "    # x shape is (batch_size, num_cells, input_dim)\n",
        "    batch_size, num_cells, input_dim = x.size()\n",
        "\n",
        "    # Reshape for mlp_pre\n",
        "    x_reshaped = x.view(-1, input_dim) # (batch_size * num_cells, input_dim)\n",
        "    h_x_reshaped = self.mlp_pre(x_reshaped) # (batch_size * num_cells, hidden_dim)\n",
        "    h_x = h_x_reshaped.view(batch_size, num_cells, self.hidden_dim) # (batch_size, num_cells, hidden_dim)\n",
        "\n",
        "\n",
        "    # Apply GCNConv. GCNConv expects (num_nodes, in_channels) and edge_index.\n",
        "    # If we have a batch of graphs, we would need a batch object.\n",
        "    # Since we have a single edge_index for all num_cells, we can apply GCNConv\n",
        "    # to the flattened features (treating all nodes across the batch as a single graph for this layer).\n",
        "    # However, the GCNConv aggregates based on edge_index. If edge_index connects nodes\n",
        "    # within each of the 'batch_size' graphs independently, this flattened approach is wrong.\n",
        "    # Assuming edge_index represents the connections for the entire set of num_cells,\n",
        "    # and each batch element is a state on this single large graph:\n",
        "\n",
        "    # Flatten h_x for GCNConv\n",
        "    h_x_flattened = h_x.view(-1, self.hidden_dim) # (batch_size * num_cells, hidden_dim)\n",
        "\n",
        "    # Apply GCNConv. Note: This assumes edge_index connects nodes across the *entire* flattened graph.\n",
        "    # If your edge_index is for a single graph of num_cells, and you want GCNConv applied\n",
        "    # independently to each graph in the batch, you would need to use a PyG Batch object.\n",
        "    h_Nx_flattened = self.conv(h_x_flattened, edge_index) # (batch_size * num_cells, hidden_dim)\n",
        "\n",
        "    # Reshape h_Nx back to include batch dimension\n",
        "    h_Nx = h_Nx_flattened.view(batch_size, num_cells, self.hidden_dim) # (batch_size, num_cells, hidden_dim)\n",
        "\n",
        "\n",
        "    # Concatenate along the feature dimension\n",
        "    h_concat = torch.cat([h_x, h_Nx], dim=2) # (batch_size, num_cells, hidden_dim + hidden_dim)\n",
        "\n",
        "    # Reshape for mlp_post\n",
        "    h_concat_reshaped = h_concat.view(-1, self.hidden_dim + self.hidden_dim) # (batch_size * num_cells, hidden_dim + hidden_dim)\n",
        "\n",
        "    out_reshaped = self.mlp_post(h_concat_reshaped) # (batch_size * num_cells, output_dim)\n",
        "\n",
        "    # Reshape output back to (batch_size, num_cells, output_dim)\n",
        "    out = out_reshaped.view(batch_size, num_cells, self.output_dim)\n",
        "\n",
        "    return out.squeeze(-1) # Squeeze the last dimension if output_dim is 1"
      ],
      "metadata": {
        "id": "jnKlOCAw5dvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now we look at using GNCA's to emulate point clouds"
      ],
      "metadata": {
        "id": "2v2TSRgVBwzK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "sNdBd8HACxZp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pygsp"
      ],
      "metadata": {
        "id": "k04NqxApDEgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pygsp"
      ],
      "metadata": {
        "id": "aFj0yAk6CxGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get graphs we test on"
      ],
      "metadata": {
        "id": "yLK_FCcADUj0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_cloud(name, **kwargs):\n",
        "  '''Credit Grattarola et al. '''\n",
        "  graph_class = getattr(pygsp.graphs, name)\n",
        "  graph = graph_class(**kwargs)\n",
        "\n",
        "  y = graph.coords\n",
        "  a = graph.W.astype(\"f4\")\n",
        "\n",
        "  #spektral version does the following:\n",
        "  #output = Graph(x=y, a=a)\n",
        "  #where Graph(x=None, a=None, e=None, y=None)\n",
        "  #a is an adjacency matrix in spektral, so must convert to a PyG version\n",
        "  #torch_geometric version:\n",
        "  edge_index = torch.tensor(a).nonzero()\n",
        "  edge_index = edge_index.t().contiguous()\n",
        "  output = pyg.data.Data(x=torch.from_numpy(y), edge_index=edge_index)\n",
        "\n",
        "  #output.name = name\n",
        "\n",
        "  return output\n",
        "\n",
        "graphs = [\n",
        "        get_cloud(\"Grid2d\", N1=20, N2=20),\n",
        "        get_cloud(\"Bunny\"),\n",
        "        get_cloud(\"Minnesota\"),\n",
        "        get_cloud(\"Logo\"),\n",
        "        get_cloud(\"SwissRoll\", N=200), #Below graphs are new graphs we want to test on\n",
        "        get_cloud(\"comet\",N=47,k=31), # primes just in case\n",
        "  `     get_cloud(\"BarabasiAlbert\"N=150) #150 node random graph according to Barabasi-Albert construction\n",
        "    ]"
      ],
      "metadata": {
        "id": "Es9J8hEBFUcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_sphere(graph):\n",
        "    offset = torch.mean(graph.x, dim=-2, keepdim=True)\n",
        "    scale = torch.abs((graph.x)).max()\n",
        "    graph.x = (graph.x - offset) / scale\n",
        "\n",
        "    return graph"
      ],
      "metadata": {
        "id": "oSSxg3OyHua0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "class stateCache:\n",
        "  '''Cache that stores states of GNCA. We sample from this for training\n",
        "  cache stored as an array of pyg dataset objects'''\n",
        "  def __init__(self, initial_state, size=1024):\n",
        "    ''' Takes as input initial_state - sphere-normalized initial state graph dataset objects'''\n",
        "    self.init_state = initial_state\n",
        "    self.counter = torch.zeros(size) #[size,] tensor for keeping count of how many times we pick from index\n",
        "    self.cache = [initial_state for i in range(size)] #array of graph dataset objects\n",
        "  def sample(self,count):\n",
        "    '''Sample count graphs from cache for training\n",
        "    Returns samples in array, and indices where chosen from'''\n",
        "    #Pick count random idxs from [0,size]\n",
        "    idxs = torch.randint(0,len(self.cache), (count,))\n",
        "    return [self.cache[i] for i in idxs], idxs\n",
        "  def update(self,idxs,states,counts):\n",
        "    '''Update cache with new states.\n",
        "    Replace random choice in cache with initial state graph'''\n",
        "    self.cache[idxs] = states\n",
        "    self.counter[idxs] += counts\n",
        "    #randomly choose index to replace with initial state\n",
        "    idx = torch.randint(0,len(self.cache), (1,))\n",
        "    self.cache[idx] = self.init_state\n",
        "    self.counter[idx] = 0\n",
        "    return\n",
        "  def initial(self):\n",
        "    return self.init_state\n",
        "\n"
      ],
      "metadata": {
        "id": "P7hf7w4jhM5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training GNCA\n",
        "'To train the GNCA, we apply the transition for a given number of steps t and use backpropagation\n",
        "through time (BPTT) to update the weights, with loss MSE\n",
        "for mini-batches\n",
        "of size K consisting of states S(k)\n",
        "for k = 1, . . . , K. This ensures that the GNCA will learn to\n",
        "converge to the target state in t steps. Second, during training, we use a cache to store the states\n",
        "$$τ^t_θ(S(k))$$ reached by the GNCA after each forward pass.\n",
        "\n",
        "Then, we use the cache as a replay memory\n",
        "and train the GNCA on batches of states S\n",
        "(k)\n",
        "sampled from the cache. For every batch, the cache\n",
        "is updated with the new states reached by the GNCA after t steps, and one element of the cache is\n",
        "replaced with S¯ to avoid catastrophic forgetting. The cache has a size of 1024 states and is initialised\n",
        "entirely with S¯. By using the cache, the GNCA is trained also on states that result from a repeated\n",
        "application of the transition function. *This strategy encourages the GNCA to remain at the target\n",
        "state after reaching it, while also ensuring an adequate exploration of the state space during training.*\n",
        "\n",
        "**In other words**, we will do **two training runs**: first, we train the GNCA on the target state. Then we train it on the cache produced by this first process, to encourage fixation to an attractor'\n"
      ],
      "metadata": {
        "id": "Pjc9urpPZ3Dr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#hyperparameters\n",
        "cache_size = 1024 #match paper definition\n",
        "batch_size = 8 #ibid lol\n",
        "batches_in_epoch = 10\n",
        "step_set = [3,5,7,11,13,17,19,23,29,31,37]\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "loss_fn = torch.nn.BCELoss()"
      ],
      "metadata": {
        "id": "-T-CNSUWqq5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run(graph,model):\n",
        "\n",
        "  def train_step(model,batch,steps,y):\n",
        "    '''steps number of training steps given our model'''\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    x = batch.x\n",
        "    for t in range(steps):\n",
        "        x = model(x, batch.edge_index)\n",
        "    print(f\"In a training step, our output's shape is {out.shape}\") #should be batch_size, y.shape[0],y.shape[1]\n",
        "    loss = loss_fn(y.expand(batch_size,y.shape[0],y.shape[1]),x)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return x, loss.item()\n",
        "\n",
        "  #history\n",
        "  history = [] #can make more complex later\n",
        "  y = graph.x\n",
        "  #init cache\n",
        "  cache = stateCache(normalize_sphere(y),size=cache_size)\n",
        "  data_list = [] #for batching. Will be comprised of pyg dataset objects\n",
        "  #loop over epochs now\n",
        "  for _ in range(epochs):\n",
        "    loss = 0\n",
        "    for j in range(batches_in_epoch):\n",
        "      #sample from cache\n",
        "      x,idxs = cache.sample(batch_size)\n",
        "\n",
        "      #pick random step size - deviate from paper and use primes for better periodicity handling\n",
        "      step_set_length = len(step_set)\n",
        "      step_idx = torch.randint(0,step_set_length,(1,))\n",
        "      step = step_set[step_idx]\n",
        "\n",
        "      #build batched data\n",
        "      data_list = []\n",
        "      for i in range(batch_size):\n",
        "        data_list.append([x[i],edge_index]) #identical edge set\n",
        "      batch = pyg.data.Batch.from_data_list(data_list) #batch our data for quicker training\n",
        "\n",
        "      #train model\n",
        "      out, loss_step = train_step(model,batch,step,y)\n",
        "      loss+=loss+step\n",
        "\n",
        "    cache.update(idxs,out,torch.ones(batch_size)*step)\n",
        "    loss/=batches_in_epoch\n",
        "    history.append(loss)\n",
        "  #after epochs are done, training done\n",
        "  return history,cache,model #come back for more detailed analytics\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OaxXTm00dW_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "now we just gotta run 'run()' function and train model!"
      ],
      "metadata": {
        "id": "ru1T5per5C_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#to do"
      ],
      "metadata": {
        "id": "m0zVBCTm5Gf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' Grattarola et al implementation:\n",
        "for graph in graphs:\n",
        "        graph = NormalizeSphere()(graph)\n",
        "\n",
        "        model = GNNCASimple(activation=args.activation, batch_norm=False)\n",
        "        optimizer = Adam(learning_rate=args.lr)\n",
        "        loss_fn = MeanSquaredError()\n",
        "\n",
        "        history, state_cache = run(graph)\n",
        "\n",
        "        # Unpack data\n",
        "        y = graph.x\n",
        "        a = sp_matrix_to_sp_tensor(graph.a)\n",
        "\n",
        "        # Run model for the twice the maximum number of steps in the cache\n",
        "        x = state_cache.initial_state()\n",
        "        x = x[None, ...]\n",
        "        steps = 2 * int(np.max(state_cache.counter))\n",
        "        zs = [x]\n",
        "        for _ in range(steps):\n",
        "            z = model([zs[-1], a], training=False)\n",
        "            zs.append(z.numpy())\n",
        "        zs = np.vstack(zs)\n",
        "        z = zs[-1]\n",
        "\n",
        "        out_dir = f\"{args.outdir}/{graph.name}\"\n",
        "        os.makedirs(out_dir, exist_ok=True)\n",
        "        with open(f\"{out_dir}/config.txt\", \"w\") as f:\n",
        "            f.writelines([f\"{k}={v}\\n\" for k, v, in vars(args).items()])\n",
        "        np.savez(f\"{out_dir}/run_point_cloud.npz\", y=y, z=z, history=history, zs=zs)\n",
        "\n",
        "        # Plot difference between target and output points\n",
        "        plt.figure(figsize=(2.5, 2.5))\n",
        "        cmap = plt.get_cmap(\"Set2\")\n",
        "        plt.scatter(*y[:, :2].T, color=cmap(0), marker=\".\", s=1)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"{out_dir}/target.pdf\")\n",
        "\n",
        "        plt.figure(figsize=(2.5, 2.5))\n",
        "        cmap = plt.get_cmap(\"Set2\")\n",
        "        plt.scatter(*z[:, :2].T, color=cmap(1), marker=\".\", s=1)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"{out_dir}/endstate.pdf\")\n",
        "\n",
        "        # Plot loss and loss trend\n",
        "        plt.figure(figsize=(2.6, 2.5))\n",
        "        cmap = plt.get_cmap(\"Set2\")\n",
        "        plt.plot(history[\"loss\"], alpha=0.3, color=cmap(0), label=\"Real\")\n",
        "        plt.plot(gaussian_filter1d(history[\"loss\"], 50), color=cmap(0), label=\"Trend\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.xscale(\"log\")\n",
        "        plt.yscale(\"log\")\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"{out_dir}/loss.pdf\")\n",
        "\n",
        "        # Plot change between consecutive state\n",
        "        plt.figure(figsize=(2.5, 2.5))\n",
        "        cmap = plt.get_cmap(\"Set2\")\n",
        "        change = np.abs(zs[:-1] - zs[1:]).mean((1, 2))\n",
        "        loss = np.array([loss_fn(y, zs[i]).numpy() for i in range(len(zs))])\n",
        "        plt.plot(change, label=\"Abs. change\", color=cmap(0))\n",
        "        plt.plot(loss, label=\"Loss\", color=cmap(1))\n",
        "        plt.xlabel(\"Step\")\n",
        "        plt.xscale(\"log\")\n",
        "        plt.yscale(\"log\")\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"{out_dir}/change.pdf\")\n",
        "\n",
        "        # Plot evolution of states\n",
        "        n_states = 10\n",
        "        plt.figure(figsize=(n_states * 2.0, 2.1))\n",
        "        for i in range(n_states):\n",
        "            plt.subplot(1, n_states, i + 1)\n",
        "            plt.scatter(*zs[i, :, :2].T, color=cmap(1), marker=\".\", s=1)\n",
        "            plt.title(f\"t={i}\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"{out_dir}/evolution.pdf\")\n",
        "\n",
        "        # Plot the average number of steps for the states in the cache\n",
        "        plt.figure(figsize=(2.5, 2.5))\n",
        "        cmap = plt.get_cmap(\"Set2\")\n",
        "        s_avg, s_std = np.array(history[\"steps_avg\"]), np.array(history[\"steps_std\"])\n",
        "        s_max, s_min = np.array(history[\"steps_max\"]), np.array(history[\"steps_min\"])\n",
        "        plt.plot(s_avg, label=\"Avg.\", color=cmap(0))\n",
        "        plt.fill_between(\n",
        "            np.arange(len(s_std)),\n",
        "            s_avg - s_std,\n",
        "            s_avg + s_std,\n",
        "            alpha=0.5,\n",
        "            color=cmap(0),\n",
        "        )\n",
        "        plt.plot(s_max, linewidth=0.5, linestyle=\"--\", color=\"k\", label=\"Max\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"Number of steps in cache\")\n",
        "        plt.legend()\n",
        "        plt.xscale(\"log\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"{out_dir}/steps_in_cache.pdf\")\n",
        "\n",
        "    plt.show()\n",
        "    '''"
      ],
      "metadata": {
        "id": "RHhHWFLODUQc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}